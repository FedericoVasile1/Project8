{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "run_PyTorch-BayesianCNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "toEsokv6uyoV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "259c7e5b-2070-4220-d1d7-e96cf150ec25"
      },
      "source": [
        "!pip install torch==1.4.0 torchvision==0.5.0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch==1.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/24/19/4804aea17cd136f1705a5e98a00618cb8f6ccc375ad8bfa437408e09d058/torch-1.4.0-cp36-cp36m-manylinux1_x86_64.whl (753.4MB)\n",
            "\u001b[K     |████████████████████████████████| 753.4MB 14kB/s \n",
            "\u001b[?25hCollecting torchvision==0.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/90/6141bf41f5655c78e24f40f710fdd4f8a8aff6c8b7c6f0328240f649bdbe/torchvision-0.5.0-cp36-cp36m-manylinux1_x86_64.whl (4.0MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0MB 51.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.5.0) (7.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision==0.5.0) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==0.5.0) (1.19.5)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Found existing installation: torch 1.7.0+cu101\n",
            "    Uninstalling torch-1.7.0+cu101:\n",
            "      Successfully uninstalled torch-1.7.0+cu101\n",
            "  Found existing installation: torchvision 0.8.1+cu101\n",
            "    Uninstalling torchvision-0.8.1+cu101:\n",
            "      Successfully uninstalled torchvision-0.8.1+cu101\n",
            "Successfully installed torch-1.4.0 torchvision-0.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHNODt9DCxO0",
        "outputId": "ffd8cecb-c2e0-4e1b-91fd-ae735747a3fb"
      },
      "source": [
        "!git clone -n https://github.com/kumar-shridhar/PyTorch-BayesianCNN\n",
        "%cd PyTorch-BayesianCNN/\n",
        "!git checkout '6ece34bfaa65cae4acb60e6d70e75bb779ba360a'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'PyTorch-BayesianCNN'...\n",
            "remote: Enumerating objects: 126, done.\u001b[K\n",
            "remote: Counting objects: 100% (126/126), done.\u001b[K\n",
            "remote: Compressing objects: 100% (80/80), done.\u001b[K\n",
            "remote: Total 1687 (delta 71), reused 87 (delta 46), pack-reused 1561\u001b[K\n",
            "Receiving objects: 100% (1687/1687), 67.83 MiB | 31.71 MiB/s, done.\n",
            "Resolving deltas: 100% (1007/1007), done.\n",
            "/content/PyTorch-BayesianCNN\n",
            "Note: checking out '6ece34bfaa65cae4acb60e6d70e75bb779ba360a'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by performing another checkout.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -b with the checkout command again. Example:\n",
            "\n",
            "  git checkout -b <new-branch-name>\n",
            "\n",
            "HEAD is now at 6ece34b Merge pull request #58 from lan-qing/master\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHoA_aVZu6NG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22e245de-1ead-4706-9b8e-64dc64ec8ff9"
      },
      "source": [
        "!python main_bayesian.py --net_type 'alexnet'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n",
            "9920512it [00:00, 32593218.24it/s]                 \n",
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "32768it [00:00, 456565.35it/s]\n",
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "1654784it [00:00, 9704498.67it/s]              \n",
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "8192it [00:00, 154561.25it/s]\n",
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "Processing...\n",
            "Done!\n",
            "Epoch: 0 \tTraining Loss: 35176679.1596 \tTraining Accuracy: 0.4529 \tValidation Loss: 25983361.8723 \tValidation Accuracy: 0.7786 \ttrain_kl_div: 347361436.0851\n",
            "Validation loss decreased (inf --> 25983361.872340).  Saving model ...\n",
            "Epoch: 1 \tTraining Loss: 21394133.6489 \tTraining Accuracy: 0.8247 \tValidation Loss: 17709759.4894 \tValidation Accuracy: 0.8537 \ttrain_kl_div: 213617646.9787\n",
            "Validation loss decreased (25983361.872340 --> 17709759.489362).  Saving model ...\n",
            "Epoch: 2 \tTraining Loss: 15226676.1968 \tTraining Accuracy: 0.8795 \tValidation Loss: 13096368.8936 \tValidation Accuracy: 0.8968 \ttrain_kl_div: 152038547.7021\n",
            "Validation loss decreased (17709759.489362 --> 13096368.893617).  Saving model ...\n",
            "Epoch: 3 \tTraining Loss: 11528243.6702 \tTraining Accuracy: 0.8943 \tValidation Loss: 10139244.9362 \tValidation Accuracy: 0.8920 \ttrain_kl_div: 115083333.1489\n",
            "Validation loss decreased (13096368.893617 --> 10139244.936170).  Saving model ...\n",
            "Epoch: 4 \tTraining Loss: 9059695.7846 \tTraining Accuracy: 0.9087 \tValidation Loss: 8086925.8404 \tValidation Accuracy: 0.9131 \ttrain_kl_div: 90423742.3830\n",
            "Validation loss decreased (10139244.936170 --> 8086925.840426).  Saving model ...\n",
            "Epoch: 5 \tTraining Loss: 7306570.7926 \tTraining Accuracy: 0.9154 \tValidation Loss: 6591663.0851 \tValidation Accuracy: 0.9216 \ttrain_kl_div: 72905752.1489\n",
            "Validation loss decreased (8086925.840426 --> 6591663.085106).  Saving model ...\n",
            "Epoch: 6 \tTraining Loss: 6006079.0266 \tTraining Accuracy: 0.9222 \tValidation Loss: 5468379.4149 \tValidation Accuracy: 0.8956 \ttrain_kl_div: 59912801.5745\n",
            "Validation loss decreased (6591663.085106 --> 5468379.414894).  Saving model ...\n",
            "Epoch: 7 \tTraining Loss: 5010651.2181 \tTraining Accuracy: 0.9230 \tValidation Loss: 4587255.5106 \tValidation Accuracy: 0.9236 \ttrain_kl_div: 49960521.6383\n",
            "Validation loss decreased (5468379.414894 --> 4587255.510638).  Saving model ...\n",
            "Epoch: 8 \tTraining Loss: 4227738.0745 \tTraining Accuracy: 0.9283 \tValidation Loss: 3888785.5957 \tValidation Accuracy: 0.9362 \ttrain_kl_div: 42140671.7234\n",
            "Validation loss decreased (4587255.510638 --> 3888785.595745).  Saving model ...\n",
            "Epoch: 9 \tTraining Loss: 3600153.6250 \tTraining Accuracy: 0.9309 \tValidation Loss: 3326303.0479 \tValidation Accuracy: 0.9313 \ttrain_kl_div: 35870928.7128\n",
            "Validation loss decreased (3888785.595745 --> 3326303.047872).  Saving model ...\n",
            "Epoch: 10 \tTraining Loss: 3088455.9934 \tTraining Accuracy: 0.9351 \tValidation Loss: 2863634.4521 \tValidation Accuracy: 0.9329 \ttrain_kl_div: 30761118.2553\n",
            "Validation loss decreased (3326303.047872 --> 2863634.452128).  Saving model ...\n",
            "Epoch: 11 \tTraining Loss: 2665999.8378 \tTraining Accuracy: 0.9369 \tValidation Loss: 2479333.8777 \tValidation Accuracy: 0.9319 \ttrain_kl_div: 26539012.1702\n",
            "Validation loss decreased (2863634.452128 --> 2479333.877660).  Saving model ...\n",
            "Epoch: 12 \tTraining Loss: 2312499.2327 \tTraining Accuracy: 0.9397 \tValidation Loss: 2154741.2500 \tValidation Accuracy: 0.9387 \ttrain_kl_div: 23010104.7872\n",
            "Validation loss decreased (2479333.877660 --> 2154741.250000).  Saving model ...\n",
            "Epoch: 13 \tTraining Loss: 2014343.4967 \tTraining Accuracy: 0.9411 \tValidation Loss: 1880459.8431 \tValidation Accuracy: 0.9394 \ttrain_kl_div: 20031502.8085\n",
            "Validation loss decreased (2154741.250000 --> 1880459.843085).  Saving model ...\n",
            "Epoch: 14 \tTraining Loss: 1760833.5319 \tTraining Accuracy: 0.9410 \tValidation Loss: 1647261.0665 \tValidation Accuracy: 0.9332 \ttrain_kl_div: 17497257.0851\n",
            "Validation loss decreased (1880459.843085 --> 1647261.066489).  Saving model ...\n",
            "Epoch: 15 \tTraining Loss: 1542878.8876 \tTraining Accuracy: 0.9453 \tValidation Loss: 1444052.8484 \tValidation Accuracy: 0.9465 \ttrain_kl_div: 15323945.1915\n",
            "Validation loss decreased (1647261.066489 --> 1444052.848404).  Saving model ...\n",
            "Epoch: 16 \tTraining Loss: 1354942.1582 \tTraining Accuracy: 0.9477 \tValidation Loss: 1269677.1569 \tValidation Accuracy: 0.9491 \ttrain_kl_div: 13449371.8138\n",
            "Validation loss decreased (1444052.848404 --> 1269677.156915).  Saving model ...\n",
            "Epoch: 17 \tTraining Loss: 1192389.0824 \tTraining Accuracy: 0.9470 \tValidation Loss: 1118047.3271 \tValidation Accuracy: 0.9491 \ttrain_kl_div: 11824413.2819\n",
            "Validation loss decreased (1269677.156915 --> 1118047.327128).  Saving model ...\n",
            "Epoch: 18 \tTraining Loss: 1050851.6041 \tTraining Accuracy: 0.9493 \tValidation Loss: 987363.5891 \tValidation Accuracy: 0.9406 \ttrain_kl_div: 10409561.6064\n",
            "Validation loss decreased (1118047.327128 --> 987363.589096).  Saving model ...\n",
            "Epoch: 19 \tTraining Loss: 926644.5336 \tTraining Accuracy: 0.9506 \tValidation Loss: 869801.3471 \tValidation Accuracy: 0.9519 \ttrain_kl_div: 9171791.0532\n",
            "Validation loss decreased (987363.589096 --> 869801.347074).  Saving model ...\n",
            "Epoch: 20 \tTraining Loss: 817974.0419 \tTraining Accuracy: 0.9513 \tValidation Loss: 767538.8311 \tValidation Accuracy: 0.9541 \ttrain_kl_div: 8086346.6144\n",
            "Validation loss decreased (869801.347074 --> 767538.831117).  Saving model ...\n",
            "Epoch: 21 \tTraining Loss: 722110.4089 \tTraining Accuracy: 0.9532 \tValidation Loss: 678244.1144 \tValidation Accuracy: 0.9533 \ttrain_kl_div: 7130934.5798\n",
            "Validation loss decreased (767538.831117 --> 678244.114362).  Saving model ...\n",
            "Epoch: 22 \tTraining Loss: 637889.3009 \tTraining Accuracy: 0.9528 \tValidation Loss: 598486.5785 \tValidation Accuracy: 0.9572 \ttrain_kl_div: 6289229.2048\n",
            "Validation loss decreased (678244.114362 --> 598486.578457).  Saving model ...\n",
            "Epoch: 23 \tTraining Loss: 563367.8185 \tTraining Accuracy: 0.9537 \tValidation Loss: 529567.3577 \tValidation Accuracy: 0.9530 \ttrain_kl_div: 5545297.4255\n",
            "Validation loss decreased (598486.578457 --> 529567.357713).  Saving model ...\n",
            "Epoch: 24 \tTraining Loss: 497150.1519 \tTraining Accuracy: 0.9571 \tValidation Loss: 467013.2812 \tValidation Accuracy: 0.9544 \ttrain_kl_div: 4887020.7500\n",
            "Validation loss decreased (529567.357713 --> 467013.281250).  Saving model ...\n",
            "Epoch: 25 \tTraining Loss: 438768.0419 \tTraining Accuracy: 0.9566 \tValidation Loss: 411348.4688 \tValidation Accuracy: 0.9593 \ttrain_kl_div: 4303859.9322\n",
            "Validation loss decreased (467013.281250 --> 411348.468750).  Saving model ...\n",
            "Epoch: 26 \tTraining Loss: 387010.8384 \tTraining Accuracy: 0.9578 \tValidation Loss: 363963.0711 \tValidation Accuracy: 0.9533 \ttrain_kl_div: 3787402.6755\n",
            "Validation loss decreased (411348.468750 --> 363963.071144).  Saving model ...\n",
            "Epoch: 27 \tTraining Loss: 341076.9136 \tTraining Accuracy: 0.9589 \tValidation Loss: 320469.0811 \tValidation Accuracy: 0.9554 \ttrain_kl_div: 3329382.5412\n",
            "Validation loss decreased (363963.071144 --> 320469.081117).  Saving model ...\n",
            "Epoch: 28 \tTraining Loss: 300633.3464 \tTraining Accuracy: 0.9579 \tValidation Loss: 282684.6090 \tValidation Accuracy: 0.9550 \ttrain_kl_div: 2923683.1184\n",
            "Validation loss decreased (320469.081117 --> 282684.609043).  Saving model ...\n",
            "Epoch: 29 \tTraining Loss: 264263.3251 \tTraining Accuracy: 0.9606 \tValidation Loss: 248159.9917 \tValidation Accuracy: 0.9582 \ttrain_kl_div: 2563427.2035\n",
            "Validation loss decreased (282684.609043 --> 248159.991689).  Saving model ...\n",
            "Epoch: 30 \tTraining Loss: 232071.8720 \tTraining Accuracy: 0.9612 \tValidation Loss: 218955.0093 \tValidation Accuracy: 0.9529 \ttrain_kl_div: 2243818.0705\n",
            "Validation loss decreased (248159.991689 --> 218955.009309).  Saving model ...\n",
            "Epoch: 31 \tTraining Loss: 204069.1448 \tTraining Accuracy: 0.9606 \tValidation Loss: 190599.2616 \tValidation Accuracy: 0.9614 \ttrain_kl_div: 1961302.0904\n",
            "Validation loss decreased (218955.009309 --> 190599.261636).  Saving model ...\n",
            "Epoch: 32 \tTraining Loss: 178493.5747 \tTraining Accuracy: 0.9629 \tValidation Loss: 168214.1679 \tValidation Accuracy: 0.9577 \ttrain_kl_div: 1710849.9814\n",
            "Validation loss decreased (190599.261636 --> 168214.167886).  Saving model ...\n",
            "Epoch: 33 \tTraining Loss: 156548.8995 \tTraining Accuracy: 0.9620 \tValidation Loss: 147163.9262 \tValidation Accuracy: 0.9580 \ttrain_kl_div: 1489757.5047\n",
            "Validation loss decreased (168214.167886 --> 147163.926197).  Saving model ...\n",
            "Epoch: 34 \tTraining Loss: 136643.9809 \tTraining Accuracy: 0.9637 \tValidation Loss: 128296.7952 \tValidation Accuracy: 0.9613 \ttrain_kl_div: 1294985.9747\n",
            "Validation loss decreased (147163.926197 --> 128296.795213).  Saving model ...\n",
            "Epoch: 35 \tTraining Loss: 119146.7864 \tTraining Accuracy: 0.9653 \tValidation Loss: 111490.1609 \tValidation Accuracy: 0.9665 \ttrain_kl_div: 1122855.1606\n",
            "Validation loss decreased (128296.795213 --> 111490.160904).  Saving model ...\n",
            "Epoch: 36 \tTraining Loss: 104444.2401 \tTraining Accuracy: 0.9643 \tValidation Loss: 97511.8329 \tValidation Accuracy: 0.9643 \ttrain_kl_div: 972767.0419\n",
            "Validation loss decreased (111490.160904 --> 97511.832945).  Saving model ...\n",
            "Epoch: 37 \tTraining Loss: 91201.4756 \tTraining Accuracy: 0.9651 \tValidation Loss: 85280.0218 \tValidation Accuracy: 0.9646 \ttrain_kl_div: 840683.7623\n",
            "Validation loss decreased (97511.832945 --> 85280.021775).  Saving model ...\n",
            "Epoch: 38 \tTraining Loss: 79094.3253 \tTraining Accuracy: 0.9671 \tValidation Loss: 74367.6398 \tValidation Accuracy: 0.9652 \ttrain_kl_div: 725088.9249\n",
            "Validation loss decreased (85280.021775 --> 74367.639794).  Saving model ...\n",
            "Epoch: 39 \tTraining Loss: 68875.6231 \tTraining Accuracy: 0.9680 \tValidation Loss: 64838.4708 \tValidation Accuracy: 0.9643 \ttrain_kl_div: 624089.4987\n",
            "Validation loss decreased (74367.639794 --> 64838.470828).  Saving model ...\n",
            "Epoch: 40 \tTraining Loss: 60137.1683 \tTraining Accuracy: 0.9677 \tValidation Loss: 56012.6939 \tValidation Accuracy: 0.9697 \ttrain_kl_div: 536970.0643\n",
            "Validation loss decreased (64838.470828 --> 56012.693900).  Saving model ...\n",
            "Epoch: 41 \tTraining Loss: 52484.1091 \tTraining Accuracy: 0.9685 \tValidation Loss: 49998.2564 \tValidation Accuracy: 0.9656 \ttrain_kl_div: 461527.6971\n",
            "Validation loss decreased (56012.693900 --> 49998.256400).  Saving model ...\n",
            "Epoch: 42 \tTraining Loss: 45727.3542 \tTraining Accuracy: 0.9699 \tValidation Loss: 43783.7108 \tValidation Accuracy: 0.9664 \ttrain_kl_div: 396251.4802\n",
            "Validation loss decreased (49998.256400 --> 43783.710771).  Saving model ...\n",
            "Epoch: 43 \tTraining Loss: 40036.2859 \tTraining Accuracy: 0.9710 \tValidation Loss: 37913.8400 \tValidation Accuracy: 0.9709 \ttrain_kl_div: 340569.8999\n",
            "Validation loss decreased (43783.710771 --> 37913.840010).  Saving model ...\n",
            "Epoch: 44 \tTraining Loss: 35255.3104 \tTraining Accuracy: 0.9713 \tValidation Loss: 33856.8897 \tValidation Accuracy: 0.9691 \ttrain_kl_div: 292757.0573\n",
            "Validation loss decreased (37913.840010 --> 33856.889711).  Saving model ...\n",
            "Epoch: 45 \tTraining Loss: 30962.9116 \tTraining Accuracy: 0.9726 \tValidation Loss: 30007.4598 \tValidation Accuracy: 0.9683 \ttrain_kl_div: 252203.6859\n",
            "Validation loss decreased (33856.889711 --> 30007.459815).  Saving model ...\n",
            "Epoch: 46 \tTraining Loss: 27612.2969 \tTraining Accuracy: 0.9719 \tValidation Loss: 26751.3890 \tValidation Accuracy: 0.9697 \ttrain_kl_div: 218271.6722\n",
            "Validation loss decreased (30007.459815 --> 26751.389046).  Saving model ...\n",
            "Epoch: 47 \tTraining Loss: 24735.0526 \tTraining Accuracy: 0.9725 \tValidation Loss: 24338.5920 \tValidation Accuracy: 0.9700 \ttrain_kl_div: 189640.3226\n",
            "Validation loss decreased (26751.389046 --> 24338.592005).  Saving model ...\n",
            "Epoch: 48 \tTraining Loss: 22161.9937 \tTraining Accuracy: 0.9727 \tValidation Loss: 21715.6323 \tValidation Accuracy: 0.9704 \ttrain_kl_div: 165812.0808\n",
            "Validation loss decreased (24338.592005 --> 21715.632314).  Saving model ...\n",
            "Epoch: 49 \tTraining Loss: 20043.6695 \tTraining Accuracy: 0.9747 \tValidation Loss: 19830.7406 \tValidation Accuracy: 0.9708 \ttrain_kl_div: 145624.1863\n",
            "Validation loss decreased (21715.632314 --> 19830.740567).  Saving model ...\n",
            "Epoch: 50 \tTraining Loss: 18210.9837 \tTraining Accuracy: 0.9744 \tValidation Loss: 18582.2075 \tValidation Accuracy: 0.9706 \ttrain_kl_div: 129223.7417\n",
            "Validation loss decreased (19830.740567 --> 18582.207488).  Saving model ...\n",
            "Epoch: 51 \tTraining Loss: 17017.1178 \tTraining Accuracy: 0.9741 \tValidation Loss: 17302.5129 \tValidation Accuracy: 0.9717 \ttrain_kl_div: 116029.7804\n",
            "Validation loss decreased (18582.207488 --> 17302.512903).  Saving model ...\n",
            "Epoch: 52 \tTraining Loss: 15506.5664 \tTraining Accuracy: 0.9754 \tValidation Loss: 16431.3875 \tValidation Accuracy: 0.9722 \ttrain_kl_div: 104906.9665\n",
            "Validation loss decreased (17302.512903 --> 16431.387529).  Saving model ...\n",
            "Epoch: 53 \tTraining Loss: 14731.5469 \tTraining Accuracy: 0.9755 \tValidation Loss: 15607.1750 \tValidation Accuracy: 0.9708 \ttrain_kl_div: 95780.4611\n",
            "Validation loss decreased (16431.387529 --> 15607.175012).  Saving model ...\n",
            "Epoch: 54 \tTraining Loss: 13709.1736 \tTraining Accuracy: 0.9765 \tValidation Loss: 14928.7474 \tValidation Accuracy: 0.9713 \ttrain_kl_div: 88766.1867\n",
            "Validation loss decreased (15607.175012 --> 14928.747403).  Saving model ...\n",
            "Epoch: 55 \tTraining Loss: 13087.6277 \tTraining Accuracy: 0.9773 \tValidation Loss: 14147.9688 \tValidation Accuracy: 0.9725 \ttrain_kl_div: 82655.5281\n",
            "Validation loss decreased (14928.747403 --> 14147.968750).  Saving model ...\n",
            "Epoch: 56 \tTraining Loss: 12527.8276 \tTraining Accuracy: 0.9783 \tValidation Loss: 13667.4020 \tValidation Accuracy: 0.9753 \ttrain_kl_div: 77732.6267\n",
            "Validation loss decreased (14147.968750 --> 13667.402011).  Saving model ...\n",
            "Epoch: 57 \tTraining Loss: 12450.2600 \tTraining Accuracy: 0.9766 \tValidation Loss: 13530.4409 \tValidation Accuracy: 0.9731 \ttrain_kl_div: 74080.8490\n",
            "Validation loss decreased (13667.402011 --> 13530.440908).  Saving model ...\n",
            "Epoch: 58 \tTraining Loss: 11812.2548 \tTraining Accuracy: 0.9778 \tValidation Loss: 13805.3581 \tValidation Accuracy: 0.9690 \ttrain_kl_div: 71214.1166\n",
            "Epoch: 59 \tTraining Loss: 11586.0890 \tTraining Accuracy: 0.9780 \tValidation Loss: 13366.9418 \tValidation Accuracy: 0.9719 \ttrain_kl_div: 68719.3649\n",
            "Validation loss decreased (13530.440908 --> 13366.941843).  Saving model ...\n",
            "Epoch: 60 \tTraining Loss: 11265.5656 \tTraining Accuracy: 0.9778 \tValidation Loss: 12092.4542 \tValidation Accuracy: 0.9751 \ttrain_kl_div: 66673.3499\n",
            "Validation loss decreased (13366.941843 --> 12092.454216).  Saving model ...\n",
            "Epoch: 61 \tTraining Loss: 11276.7154 \tTraining Accuracy: 0.9779 \tValidation Loss: 12364.9652 \tValidation Accuracy: 0.9726 \ttrain_kl_div: 65172.4334\n",
            "Epoch: 62 \tTraining Loss: 11082.6875 \tTraining Accuracy: 0.9779 \tValidation Loss: 12350.0317 \tValidation Accuracy: 0.9739 \ttrain_kl_div: 64230.9670\n",
            "Epoch: 63 \tTraining Loss: 10579.1649 \tTraining Accuracy: 0.9797 \tValidation Loss: 12360.6359 \tValidation Accuracy: 0.9724 \ttrain_kl_div: 62440.6219\n",
            "Epoch: 64 \tTraining Loss: 10400.7258 \tTraining Accuracy: 0.9803 \tValidation Loss: 11446.0254 \tValidation Accuracy: 0.9774 \ttrain_kl_div: 61504.8885\n",
            "Validation loss decreased (12092.454216 --> 11446.025411).  Saving model ...\n",
            "Epoch: 65 \tTraining Loss: 10401.2604 \tTraining Accuracy: 0.9800 \tValidation Loss: 11869.3129 \tValidation Accuracy: 0.9737 \ttrain_kl_div: 60839.4063\n",
            "Epoch: 66 \tTraining Loss: 10213.5886 \tTraining Accuracy: 0.9798 \tValidation Loss: 11588.4143 \tValidation Accuracy: 0.9754 \ttrain_kl_div: 59998.0151\n",
            "Epoch: 67 \tTraining Loss: 10305.0929 \tTraining Accuracy: 0.9799 \tValidation Loss: 11016.5610 \tValidation Accuracy: 0.9755 \ttrain_kl_div: 59475.2987\n",
            "Validation loss decreased (11446.025411 --> 11016.561004).  Saving model ...\n",
            "Epoch: 68 \tTraining Loss: 10137.6561 \tTraining Accuracy: 0.9794 \tValidation Loss: 11386.8697 \tValidation Accuracy: 0.9772 \ttrain_kl_div: 58961.5145\n",
            "Epoch: 69 \tTraining Loss: 10035.0533 \tTraining Accuracy: 0.9805 \tValidation Loss: 11590.9219 \tValidation Accuracy: 0.9757 \ttrain_kl_div: 58597.0345\n",
            "Epoch: 70 \tTraining Loss: 9960.2601 \tTraining Accuracy: 0.9803 \tValidation Loss: 11201.1244 \tValidation Accuracy: 0.9758 \ttrain_kl_div: 58502.4789\n",
            "Epoch: 71 \tTraining Loss: 9797.7822 \tTraining Accuracy: 0.9811 \tValidation Loss: 11738.1662 \tValidation Accuracy: 0.9735 \ttrain_kl_div: 57997.6468\n",
            "Epoch: 72 \tTraining Loss: 9546.6243 \tTraining Accuracy: 0.9818 \tValidation Loss: 10563.8227 \tValidation Accuracy: 0.9784 \ttrain_kl_div: 57637.7330\n",
            "Validation loss decreased (11016.561004 --> 10563.822692).  Saving model ...\n",
            "Epoch: 73 \tTraining Loss: 9459.1186 \tTraining Accuracy: 0.9823 \tValidation Loss: 10654.8457 \tValidation Accuracy: 0.9788 \ttrain_kl_div: 56966.9621\n",
            "Epoch: 74 \tTraining Loss: 9636.2236 \tTraining Accuracy: 0.9815 \tValidation Loss: 10923.9261 \tValidation Accuracy: 0.9780 \ttrain_kl_div: 57389.7789\n",
            "Epoch: 75 \tTraining Loss: 9457.2029 \tTraining Accuracy: 0.9823 \tValidation Loss: 11498.8344 \tValidation Accuracy: 0.9757 \ttrain_kl_div: 56863.6563\n",
            "Epoch: 76 \tTraining Loss: 9632.6517 \tTraining Accuracy: 0.9816 \tValidation Loss: 10869.3255 \tValidation Accuracy: 0.9776 \ttrain_kl_div: 56564.7382\n",
            "Epoch: 77 \tTraining Loss: 9410.3315 \tTraining Accuracy: 0.9826 \tValidation Loss: 11390.8628 \tValidation Accuracy: 0.9770 \ttrain_kl_div: 56284.6348\n",
            "Epoch: 78 \tTraining Loss: 9351.4087 \tTraining Accuracy: 0.9823 \tValidation Loss: 11077.9251 \tValidation Accuracy: 0.9784 \ttrain_kl_div: 55950.2479\n",
            "Epoch    80: reducing learning rate of group 0 to 1.0000e-04.\n",
            "Epoch: 79 \tTraining Loss: 9303.6633 \tTraining Accuracy: 0.9822 \tValidation Loss: 11459.6202 \tValidation Accuracy: 0.9749 \ttrain_kl_div: 55591.2155\n",
            "Epoch: 80 \tTraining Loss: 8842.2001 \tTraining Accuracy: 0.9843 \tValidation Loss: 10086.6323 \tValidation Accuracy: 0.9788 \ttrain_kl_div: 55116.5023\n",
            "Validation loss decreased (10563.822692 --> 10086.632262).  Saving model ...\n",
            "Epoch: 81 \tTraining Loss: 8495.1803 \tTraining Accuracy: 0.9851 \tValidation Loss: 9985.9065 \tValidation Accuracy: 0.9799 \ttrain_kl_div: 54067.9443\n",
            "Validation loss decreased (10086.632262 --> 9985.906499).  Saving model ...\n",
            "Epoch: 82 \tTraining Loss: 8374.6256 \tTraining Accuracy: 0.9850 \tValidation Loss: 9796.5772 \tValidation Accuracy: 0.9789 \ttrain_kl_div: 53183.0991\n",
            "Validation loss decreased (9985.906499 --> 9796.577190).  Saving model ...\n",
            "Epoch: 83 \tTraining Loss: 8458.1106 \tTraining Accuracy: 0.9849 \tValidation Loss: 10259.4119 \tValidation Accuracy: 0.9786 \ttrain_kl_div: 52529.9680\n",
            "Epoch: 84 \tTraining Loss: 8262.5823 \tTraining Accuracy: 0.9855 \tValidation Loss: 9807.6976 \tValidation Accuracy: 0.9786 \ttrain_kl_div: 51958.5745\n",
            "Epoch: 85 \tTraining Loss: 8122.0239 \tTraining Accuracy: 0.9852 \tValidation Loss: 9744.6150 \tValidation Accuracy: 0.9786 \ttrain_kl_div: 51429.8176\n",
            "Validation loss decreased (9796.577190 --> 9744.615016).  Saving model ...\n",
            "Epoch: 86 \tTraining Loss: 8229.2127 \tTraining Accuracy: 0.9851 \tValidation Loss: 9950.1564 \tValidation Accuracy: 0.9793 \ttrain_kl_div: 50982.1596\n",
            "Epoch: 87 \tTraining Loss: 8134.9669 \tTraining Accuracy: 0.9855 \tValidation Loss: 10163.6806 \tValidation Accuracy: 0.9790 \ttrain_kl_div: 50585.5133\n",
            "Epoch: 88 \tTraining Loss: 7910.9263 \tTraining Accuracy: 0.9861 \tValidation Loss: 9934.1578 \tValidation Accuracy: 0.9799 \ttrain_kl_div: 50210.9805\n",
            "Epoch: 89 \tTraining Loss: 8181.9534 \tTraining Accuracy: 0.9848 \tValidation Loss: 9674.9426 \tValidation Accuracy: 0.9792 \ttrain_kl_div: 49907.8869\n",
            "Validation loss decreased (9744.615016 --> 9674.942601).  Saving model ...\n",
            "Epoch: 90 \tTraining Loss: 7939.3017 \tTraining Accuracy: 0.9852 \tValidation Loss: 9751.0392 \tValidation Accuracy: 0.9794 \ttrain_kl_div: 49701.7702\n",
            "Epoch: 91 \tTraining Loss: 7979.2112 \tTraining Accuracy: 0.9851 \tValidation Loss: 10139.3661 \tValidation Accuracy: 0.9767 \ttrain_kl_div: 49446.6921\n",
            "Epoch: 92 \tTraining Loss: 7983.5806 \tTraining Accuracy: 0.9849 \tValidation Loss: 9906.5179 \tValidation Accuracy: 0.9787 \ttrain_kl_div: 49236.9220\n",
            "Epoch: 93 \tTraining Loss: 8023.5639 \tTraining Accuracy: 0.9852 \tValidation Loss: 9483.8152 \tValidation Accuracy: 0.9797 \ttrain_kl_div: 49026.9025\n",
            "Validation loss decreased (9674.942601 --> 9483.815201).  Saving model ...\n",
            "Epoch: 94 \tTraining Loss: 8112.0306 \tTraining Accuracy: 0.9846 \tValidation Loss: 10059.3195 \tValidation Accuracy: 0.9774 \ttrain_kl_div: 48839.9707\n",
            "Epoch: 95 \tTraining Loss: 7932.6880 \tTraining Accuracy: 0.9845 \tValidation Loss: 9802.1091 \tValidation Accuracy: 0.9790 \ttrain_kl_div: 48726.8919\n",
            "Epoch: 96 \tTraining Loss: 8052.6929 \tTraining Accuracy: 0.9851 \tValidation Loss: 9940.9073 \tValidation Accuracy: 0.9779 \ttrain_kl_div: 48565.2303\n",
            "Epoch: 97 \tTraining Loss: 8066.5821 \tTraining Accuracy: 0.9846 \tValidation Loss: 9865.6036 \tValidation Accuracy: 0.9784 \ttrain_kl_div: 48447.7235\n",
            "Epoch: 98 \tTraining Loss: 7838.0110 \tTraining Accuracy: 0.9857 \tValidation Loss: 9512.5161 \tValidation Accuracy: 0.9818 \ttrain_kl_div: 48264.0219\n",
            "Epoch: 99 \tTraining Loss: 7830.5262 \tTraining Accuracy: 0.9855 \tValidation Loss: 9799.6261 \tValidation Accuracy: 0.9781 \ttrain_kl_div: 48089.6787\n",
            "Epoch   101: reducing learning rate of group 0 to 1.0000e-05.\n",
            "Epoch: 100 \tTraining Loss: 8066.5649 \tTraining Accuracy: 0.9844 \tValidation Loss: 9715.6485 \tValidation Accuracy: 0.9793 \ttrain_kl_div: 47978.8452\n",
            "Epoch: 101 \tTraining Loss: 7879.7932 \tTraining Accuracy: 0.9849 \tValidation Loss: 9659.9812 \tValidation Accuracy: 0.9780 \ttrain_kl_div: 47852.3852\n",
            "Epoch: 102 \tTraining Loss: 7844.7405 \tTraining Accuracy: 0.9856 \tValidation Loss: 9382.6161 \tValidation Accuracy: 0.9789 \ttrain_kl_div: 47820.3025\n",
            "Validation loss decreased (9483.815201 --> 9382.616097).  Saving model ...\n",
            "Epoch: 103 \tTraining Loss: 7694.4989 \tTraining Accuracy: 0.9854 \tValidation Loss: 9699.8352 \tValidation Accuracy: 0.9780 \ttrain_kl_div: 47786.1341\n",
            "Epoch: 104 \tTraining Loss: 7805.8629 \tTraining Accuracy: 0.9850 \tValidation Loss: 9825.6979 \tValidation Accuracy: 0.9779 \ttrain_kl_div: 47749.3929\n",
            "Epoch: 105 \tTraining Loss: 7824.2187 \tTraining Accuracy: 0.9851 \tValidation Loss: 9285.6818 \tValidation Accuracy: 0.9799 \ttrain_kl_div: 47724.8172\n",
            "Validation loss decreased (9382.616097 --> 9285.681765).  Saving model ...\n",
            "Epoch: 106 \tTraining Loss: 7818.7387 \tTraining Accuracy: 0.9847 \tValidation Loss: 9522.1052 \tValidation Accuracy: 0.9791 \ttrain_kl_div: 47700.7216\n",
            "Epoch: 107 \tTraining Loss: 7807.0307 \tTraining Accuracy: 0.9854 \tValidation Loss: 9801.5536 \tValidation Accuracy: 0.9782 \ttrain_kl_div: 47670.2608\n",
            "Epoch: 108 \tTraining Loss: 7667.9750 \tTraining Accuracy: 0.9856 \tValidation Loss: 9590.1780 \tValidation Accuracy: 0.9793 \ttrain_kl_div: 47636.1015\n",
            "Epoch: 109 \tTraining Loss: 7701.1392 \tTraining Accuracy: 0.9860 \tValidation Loss: 9559.7614 \tValidation Accuracy: 0.9785 \ttrain_kl_div: 47605.8905\n",
            "Epoch: 110 \tTraining Loss: 7546.4337 \tTraining Accuracy: 0.9863 \tValidation Loss: 9643.9036 \tValidation Accuracy: 0.9788 \ttrain_kl_div: 47570.8436\n",
            "Epoch: 111 \tTraining Loss: 7679.6121 \tTraining Accuracy: 0.9856 \tValidation Loss: 9717.4354 \tValidation Accuracy: 0.9789 \ttrain_kl_div: 47538.9673\n",
            "Epoch   113: reducing learning rate of group 0 to 1.0000e-06.\n",
            "Epoch: 112 \tTraining Loss: 7742.8656 \tTraining Accuracy: 0.9850 \tValidation Loss: 9730.7886 \tValidation Accuracy: 0.9783 \ttrain_kl_div: 47511.1551\n",
            "Epoch: 113 \tTraining Loss: 7621.5469 \tTraining Accuracy: 0.9862 \tValidation Loss: 9868.4744 \tValidation Accuracy: 0.9763 \ttrain_kl_div: 47492.9032\n",
            "Epoch: 114 \tTraining Loss: 7381.2125 \tTraining Accuracy: 0.9871 \tValidation Loss: 9666.2525 \tValidation Accuracy: 0.9799 \ttrain_kl_div: 47489.7150\n",
            "Epoch: 115 \tTraining Loss: 7753.9919 \tTraining Accuracy: 0.9854 \tValidation Loss: 9782.5686 \tValidation Accuracy: 0.9793 \ttrain_kl_div: 47486.7383\n",
            "Epoch: 116 \tTraining Loss: 7632.8147 \tTraining Accuracy: 0.9858 \tValidation Loss: 9572.8327 \tValidation Accuracy: 0.9785 \ttrain_kl_div: 47484.8028\n",
            "Epoch: 117 \tTraining Loss: 7712.1029 \tTraining Accuracy: 0.9854 \tValidation Loss: 9658.1372 \tValidation Accuracy: 0.9792 \ttrain_kl_div: 47482.1580\n",
            "Epoch: 118 \tTraining Loss: 7811.4810 \tTraining Accuracy: 0.9855 \tValidation Loss: 9725.3469 \tValidation Accuracy: 0.9796 \ttrain_kl_div: 47480.5513\n",
            "Epoch   120: reducing learning rate of group 0 to 1.0000e-07.\n",
            "Epoch: 119 \tTraining Loss: 7709.0825 \tTraining Accuracy: 0.9855 \tValidation Loss: 9849.0519 \tValidation Accuracy: 0.9775 \ttrain_kl_div: 47478.4843\n",
            "Epoch: 120 \tTraining Loss: 7623.6736 \tTraining Accuracy: 0.9863 \tValidation Loss: 9808.3423 \tValidation Accuracy: 0.9787 \ttrain_kl_div: 47477.2512\n",
            "Epoch: 121 \tTraining Loss: 7825.5594 \tTraining Accuracy: 0.9858 \tValidation Loss: 9686.6256 \tValidation Accuracy: 0.9791 \ttrain_kl_div: 47477.0469\n",
            "Epoch: 122 \tTraining Loss: 7777.6047 \tTraining Accuracy: 0.9856 \tValidation Loss: 9819.8981 \tValidation Accuracy: 0.9793 \ttrain_kl_div: 47476.9316\n",
            "Traceback (most recent call last):\n",
            "  File \"main_bayesian.py\", line 142, in <module>\n",
            "    run(args.dataset, args.net_type)\n",
            "  File \"main_bayesian.py\", line 122, in run\n",
            "    train_loss, train_acc, train_kl = train_model(net, optimizer, criterion, train_loader, num_ens=train_ens, beta_type=beta_type, epoch=epoch, num_epochs=n_epochs)\n",
            "  File \"main_bayesian.py\", line 40, in train_model\n",
            "    optimizer.zero_grad()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/optim/optimizer.py\", line 164, in zero_grad\n",
            "    p.grad.detach_()\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73giyr62vWiw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4dab2b3-7a45-4282-acf9-2dff5a4e01eb"
      },
      "source": [
        "!python main_frequentist.py --net_type 'alexnet'"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 \tTraining Loss: 0.5420 \tTraining Accuracy: 0.7632 \tValidation Loss: 0.0409 \tValidation Accuracy: 0.9639\n",
            "Validation loss decreased (inf --> 0.040949).  Saving model ...\n",
            "Epoch: 2 \tTraining Loss: 0.1187 \tTraining Accuracy: 0.9560 \tValidation Loss: 0.0283 \tValidation Accuracy: 0.9788\n",
            "Validation loss decreased (0.040949 --> 0.028294).  Saving model ...\n",
            "Epoch: 3 \tTraining Loss: 0.0851 \tTraining Accuracy: 0.9676 \tValidation Loss: 0.0201 \tValidation Accuracy: 0.9824\n",
            "Validation loss decreased (0.028294 --> 0.020067).  Saving model ...\n",
            "Epoch: 4 \tTraining Loss: 0.0714 \tTraining Accuracy: 0.9730 \tValidation Loss: 0.0215 \tValidation Accuracy: 0.9859\n",
            "Epoch: 5 \tTraining Loss: 0.0663 \tTraining Accuracy: 0.9754 \tValidation Loss: 0.0142 \tValidation Accuracy: 0.9857\n",
            "Validation loss decreased (0.020067 --> 0.014223).  Saving model ...\n",
            "Epoch: 6 \tTraining Loss: 0.0572 \tTraining Accuracy: 0.9784 \tValidation Loss: 0.0144 \tValidation Accuracy: 0.9869\n",
            "Epoch: 7 \tTraining Loss: 0.0540 \tTraining Accuracy: 0.9805 \tValidation Loss: 0.0145 \tValidation Accuracy: 0.9867\n",
            "Epoch: 8 \tTraining Loss: 0.0500 \tTraining Accuracy: 0.9813 \tValidation Loss: 0.0126 \tValidation Accuracy: 0.9873\n",
            "Validation loss decreased (0.014223 --> 0.012600).  Saving model ...\n",
            "Epoch: 9 \tTraining Loss: 0.0434 \tTraining Accuracy: 0.9836 \tValidation Loss: 0.0110 \tValidation Accuracy: 0.9862\n",
            "Validation loss decreased (0.012600 --> 0.011003).  Saving model ...\n",
            "Epoch: 10 \tTraining Loss: 0.0420 \tTraining Accuracy: 0.9843 \tValidation Loss: 0.0088 \tValidation Accuracy: 0.9884\n",
            "Validation loss decreased (0.011003 --> 0.008764).  Saving model ...\n",
            "Epoch: 11 \tTraining Loss: 0.0393 \tTraining Accuracy: 0.9842 \tValidation Loss: 0.0108 \tValidation Accuracy: 0.9868\n",
            "Epoch: 12 \tTraining Loss: 0.0377 \tTraining Accuracy: 0.9854 \tValidation Loss: 0.0092 \tValidation Accuracy: 0.9884\n",
            "Epoch: 13 \tTraining Loss: 0.0340 \tTraining Accuracy: 0.9872 \tValidation Loss: 0.0087 \tValidation Accuracy: 0.9902\n",
            "Validation loss decreased (0.008764 --> 0.008666).  Saving model ...\n",
            "Epoch: 14 \tTraining Loss: 0.0346 \tTraining Accuracy: 0.9873 \tValidation Loss: 0.0095 \tValidation Accuracy: 0.9902\n",
            "Epoch: 15 \tTraining Loss: 0.0351 \tTraining Accuracy: 0.9874 \tValidation Loss: 0.0091 \tValidation Accuracy: 0.9890\n",
            "Epoch: 16 \tTraining Loss: 0.0338 \tTraining Accuracy: 0.9874 \tValidation Loss: 0.0098 \tValidation Accuracy: 0.9893\n",
            "Epoch: 17 \tTraining Loss: 0.0293 \tTraining Accuracy: 0.9891 \tValidation Loss: 0.0070 \tValidation Accuracy: 0.9907\n",
            "Validation loss decreased (0.008666 --> 0.006964).  Saving model ...\n",
            "Epoch: 18 \tTraining Loss: 0.0293 \tTraining Accuracy: 0.9889 \tValidation Loss: 0.0084 \tValidation Accuracy: 0.9879\n",
            "Epoch: 19 \tTraining Loss: 0.0304 \tTraining Accuracy: 0.9887 \tValidation Loss: 0.0079 \tValidation Accuracy: 0.9893\n",
            "Epoch: 20 \tTraining Loss: 0.0299 \tTraining Accuracy: 0.9883 \tValidation Loss: 0.0097 \tValidation Accuracy: 0.9880\n",
            "Epoch: 21 \tTraining Loss: 0.0280 \tTraining Accuracy: 0.9894 \tValidation Loss: 0.0074 \tValidation Accuracy: 0.9907\n",
            "Epoch: 22 \tTraining Loss: 0.0245 \tTraining Accuracy: 0.9906 \tValidation Loss: 0.0079 \tValidation Accuracy: 0.9893\n",
            "Epoch: 23 \tTraining Loss: 0.0244 \tTraining Accuracy: 0.9908 \tValidation Loss: 0.0078 \tValidation Accuracy: 0.9879\n",
            "Epoch    24: reducing learning rate of group 0 to 1.0000e-04.\n",
            "Epoch: 24 \tTraining Loss: 0.0259 \tTraining Accuracy: 0.9900 \tValidation Loss: 0.0070 \tValidation Accuracy: 0.9902\n",
            "Epoch: 25 \tTraining Loss: 0.0162 \tTraining Accuracy: 0.9934 \tValidation Loss: 0.0059 \tValidation Accuracy: 0.9919\n",
            "Validation loss decreased (0.006964 --> 0.005862).  Saving model ...\n",
            "Epoch: 26 \tTraining Loss: 0.0127 \tTraining Accuracy: 0.9943 \tValidation Loss: 0.0056 \tValidation Accuracy: 0.9926\n",
            "Validation loss decreased (0.005862 --> 0.005552).  Saving model ...\n",
            "Epoch: 27 \tTraining Loss: 0.0124 \tTraining Accuracy: 0.9950 \tValidation Loss: 0.0056 \tValidation Accuracy: 0.9923\n",
            "Epoch: 28 \tTraining Loss: 0.0120 \tTraining Accuracy: 0.9953 \tValidation Loss: 0.0055 \tValidation Accuracy: 0.9917\n",
            "Validation loss decreased (0.005552 --> 0.005498).  Saving model ...\n",
            "Epoch: 29 \tTraining Loss: 0.0100 \tTraining Accuracy: 0.9959 \tValidation Loss: 0.0054 \tValidation Accuracy: 0.9924\n",
            "Validation loss decreased (0.005498 --> 0.005438).  Saving model ...\n",
            "Epoch: 30 \tTraining Loss: 0.0096 \tTraining Accuracy: 0.9958 \tValidation Loss: 0.0055 \tValidation Accuracy: 0.9923\n",
            "Epoch: 31 \tTraining Loss: 0.0110 \tTraining Accuracy: 0.9955 \tValidation Loss: 0.0054 \tValidation Accuracy: 0.9928\n",
            "Validation loss decreased (0.005438 --> 0.005402).  Saving model ...\n",
            "Epoch: 32 \tTraining Loss: 0.0098 \tTraining Accuracy: 0.9963 \tValidation Loss: 0.0053 \tValidation Accuracy: 0.9922\n",
            "Validation loss decreased (0.005402 --> 0.005344).  Saving model ...\n",
            "Epoch: 33 \tTraining Loss: 0.0092 \tTraining Accuracy: 0.9963 \tValidation Loss: 0.0053 \tValidation Accuracy: 0.9924\n",
            "Validation loss decreased (0.005344 --> 0.005279).  Saving model ...\n",
            "Epoch: 34 \tTraining Loss: 0.0096 \tTraining Accuracy: 0.9961 \tValidation Loss: 0.0054 \tValidation Accuracy: 0.9927\n",
            "Epoch: 35 \tTraining Loss: 0.0084 \tTraining Accuracy: 0.9965 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9927\n",
            "Validation loss decreased (0.005279 --> 0.005210).  Saving model ...\n",
            "Epoch: 36 \tTraining Loss: 0.0085 \tTraining Accuracy: 0.9965 \tValidation Loss: 0.0053 \tValidation Accuracy: 0.9923\n",
            "Epoch: 37 \tTraining Loss: 0.0076 \tTraining Accuracy: 0.9969 \tValidation Loss: 0.0053 \tValidation Accuracy: 0.9919\n",
            "Epoch: 38 \tTraining Loss: 0.0074 \tTraining Accuracy: 0.9970 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9928\n",
            "Epoch: 39 \tTraining Loss: 0.0072 \tTraining Accuracy: 0.9970 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9927\n",
            "Validation loss decreased (0.005210 --> 0.005159).  Saving model ...\n",
            "Epoch: 40 \tTraining Loss: 0.0064 \tTraining Accuracy: 0.9972 \tValidation Loss: 0.0051 \tValidation Accuracy: 0.9925\n",
            "Validation loss decreased (0.005159 --> 0.005118).  Saving model ...\n",
            "Epoch: 41 \tTraining Loss: 0.0080 \tTraining Accuracy: 0.9967 \tValidation Loss: 0.0051 \tValidation Accuracy: 0.9923\n",
            "Epoch: 42 \tTraining Loss: 0.0082 \tTraining Accuracy: 0.9967 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9926\n",
            "Epoch: 43 \tTraining Loss: 0.0074 \tTraining Accuracy: 0.9970 \tValidation Loss: 0.0055 \tValidation Accuracy: 0.9923\n",
            "Epoch: 44 \tTraining Loss: 0.0072 \tTraining Accuracy: 0.9971 \tValidation Loss: 0.0053 \tValidation Accuracy: 0.9925\n",
            "Epoch: 45 \tTraining Loss: 0.0079 \tTraining Accuracy: 0.9968 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9924\n",
            "Epoch: 46 \tTraining Loss: 0.0067 \tTraining Accuracy: 0.9972 \tValidation Loss: 0.0053 \tValidation Accuracy: 0.9927\n",
            "Epoch: 47 \tTraining Loss: 0.0068 \tTraining Accuracy: 0.9972 \tValidation Loss: 0.0050 \tValidation Accuracy: 0.9931\n",
            "Validation loss decreased (0.005118 --> 0.005043).  Saving model ...\n",
            "Epoch: 48 \tTraining Loss: 0.0074 \tTraining Accuracy: 0.9968 \tValidation Loss: 0.0051 \tValidation Accuracy: 0.9924\n",
            "Epoch: 49 \tTraining Loss: 0.0060 \tTraining Accuracy: 0.9975 \tValidation Loss: 0.0051 \tValidation Accuracy: 0.9927\n",
            "Epoch: 50 \tTraining Loss: 0.0068 \tTraining Accuracy: 0.9969 \tValidation Loss: 0.0049 \tValidation Accuracy: 0.9931\n",
            "Validation loss decreased (0.005043 --> 0.004941).  Saving model ...\n",
            "Epoch: 51 \tTraining Loss: 0.0051 \tTraining Accuracy: 0.9979 \tValidation Loss: 0.0050 \tValidation Accuracy: 0.9932\n",
            "Epoch: 52 \tTraining Loss: 0.0057 \tTraining Accuracy: 0.9977 \tValidation Loss: 0.0051 \tValidation Accuracy: 0.9927\n",
            "Epoch: 53 \tTraining Loss: 0.0056 \tTraining Accuracy: 0.9979 \tValidation Loss: 0.0051 \tValidation Accuracy: 0.9927\n",
            "Epoch: 54 \tTraining Loss: 0.0064 \tTraining Accuracy: 0.9974 \tValidation Loss: 0.0051 \tValidation Accuracy: 0.9921\n",
            "Epoch: 55 \tTraining Loss: 0.0066 \tTraining Accuracy: 0.9973 \tValidation Loss: 0.0051 \tValidation Accuracy: 0.9926\n",
            "Epoch: 56 \tTraining Loss: 0.0059 \tTraining Accuracy: 0.9975 \tValidation Loss: 0.0051 \tValidation Accuracy: 0.9927\n",
            "Epoch    57: reducing learning rate of group 0 to 1.0000e-05.\n",
            "Epoch: 57 \tTraining Loss: 0.0055 \tTraining Accuracy: 0.9980 \tValidation Loss: 0.0054 \tValidation Accuracy: 0.9925\n",
            "Epoch: 58 \tTraining Loss: 0.0062 \tTraining Accuracy: 0.9974 \tValidation Loss: 0.0053 \tValidation Accuracy: 0.9924\n",
            "Epoch: 59 \tTraining Loss: 0.0057 \tTraining Accuracy: 0.9978 \tValidation Loss: 0.0053 \tValidation Accuracy: 0.9923\n",
            "Epoch: 60 \tTraining Loss: 0.0049 \tTraining Accuracy: 0.9980 \tValidation Loss: 0.0053 \tValidation Accuracy: 0.9923\n",
            "Epoch: 61 \tTraining Loss: 0.0051 \tTraining Accuracy: 0.9977 \tValidation Loss: 0.0053 \tValidation Accuracy: 0.9923\n",
            "Epoch: 62 \tTraining Loss: 0.0045 \tTraining Accuracy: 0.9980 \tValidation Loss: 0.0053 \tValidation Accuracy: 0.9922\n",
            "Epoch: 63 \tTraining Loss: 0.0047 \tTraining Accuracy: 0.9981 \tValidation Loss: 0.0053 \tValidation Accuracy: 0.9925\n",
            "Epoch    64: reducing learning rate of group 0 to 1.0000e-06.\n",
            "Epoch: 64 \tTraining Loss: 0.0044 \tTraining Accuracy: 0.9980 \tValidation Loss: 0.0053 \tValidation Accuracy: 0.9927\n",
            "Epoch: 65 \tTraining Loss: 0.0048 \tTraining Accuracy: 0.9979 \tValidation Loss: 0.0053 \tValidation Accuracy: 0.9927\n",
            "Epoch: 66 \tTraining Loss: 0.0042 \tTraining Accuracy: 0.9983 \tValidation Loss: 0.0053 \tValidation Accuracy: 0.9926\n",
            "Epoch: 67 \tTraining Loss: 0.0042 \tTraining Accuracy: 0.9983 \tValidation Loss: 0.0053 \tValidation Accuracy: 0.9926\n",
            "Epoch: 68 \tTraining Loss: 0.0049 \tTraining Accuracy: 0.9980 \tValidation Loss: 0.0053 \tValidation Accuracy: 0.9927\n",
            "Epoch: 69 \tTraining Loss: 0.0049 \tTraining Accuracy: 0.9980 \tValidation Loss: 0.0053 \tValidation Accuracy: 0.9926\n",
            "Epoch: 70 \tTraining Loss: 0.0054 \tTraining Accuracy: 0.9977 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9926\n",
            "Epoch    71: reducing learning rate of group 0 to 1.0000e-07.\n",
            "Epoch: 71 \tTraining Loss: 0.0043 \tTraining Accuracy: 0.9979 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Epoch: 72 \tTraining Loss: 0.0049 \tTraining Accuracy: 0.9980 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Epoch: 73 \tTraining Loss: 0.0046 \tTraining Accuracy: 0.9980 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Epoch: 74 \tTraining Loss: 0.0051 \tTraining Accuracy: 0.9982 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Epoch: 75 \tTraining Loss: 0.0052 \tTraining Accuracy: 0.9979 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Epoch: 76 \tTraining Loss: 0.0043 \tTraining Accuracy: 0.9984 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Epoch: 77 \tTraining Loss: 0.0045 \tTraining Accuracy: 0.9982 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Epoch    78: reducing learning rate of group 0 to 1.0000e-08.\n",
            "Epoch: 78 \tTraining Loss: 0.0049 \tTraining Accuracy: 0.9980 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Epoch: 79 \tTraining Loss: 0.0041 \tTraining Accuracy: 0.9983 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Epoch: 80 \tTraining Loss: 0.0047 \tTraining Accuracy: 0.9981 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Epoch: 81 \tTraining Loss: 0.0042 \tTraining Accuracy: 0.9984 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Epoch: 82 \tTraining Loss: 0.0047 \tTraining Accuracy: 0.9979 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Epoch: 83 \tTraining Loss: 0.0046 \tTraining Accuracy: 0.9981 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Epoch: 84 \tTraining Loss: 0.0048 \tTraining Accuracy: 0.9979 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Epoch: 85 \tTraining Loss: 0.0042 \tTraining Accuracy: 0.9981 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Epoch: 86 \tTraining Loss: 0.0048 \tTraining Accuracy: 0.9979 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Epoch: 87 \tTraining Loss: 0.0050 \tTraining Accuracy: 0.9980 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Epoch: 88 \tTraining Loss: 0.0045 \tTraining Accuracy: 0.9981 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Epoch: 89 \tTraining Loss: 0.0047 \tTraining Accuracy: 0.9980 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Epoch: 90 \tTraining Loss: 0.0056 \tTraining Accuracy: 0.9979 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Epoch: 91 \tTraining Loss: 0.0054 \tTraining Accuracy: 0.9979 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Epoch: 92 \tTraining Loss: 0.0051 \tTraining Accuracy: 0.9980 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Epoch: 93 \tTraining Loss: 0.0042 \tTraining Accuracy: 0.9982 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Epoch: 94 \tTraining Loss: 0.0044 \tTraining Accuracy: 0.9981 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Epoch: 95 \tTraining Loss: 0.0049 \tTraining Accuracy: 0.9982 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Epoch: 96 \tTraining Loss: 0.0042 \tTraining Accuracy: 0.9982 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Epoch: 97 \tTraining Loss: 0.0048 \tTraining Accuracy: 0.9978 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Epoch: 98 \tTraining Loss: 0.0047 \tTraining Accuracy: 0.9980 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Epoch: 99 \tTraining Loss: 0.0050 \tTraining Accuracy: 0.9981 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Epoch: 100 \tTraining Loss: 0.0047 \tTraining Accuracy: 0.9979 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Epoch: 101 \tTraining Loss: 0.0055 \tTraining Accuracy: 0.9976 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Epoch: 102 \tTraining Loss: 0.0046 \tTraining Accuracy: 0.9979 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Epoch: 103 \tTraining Loss: 0.0051 \tTraining Accuracy: 0.9978 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Epoch: 104 \tTraining Loss: 0.0049 \tTraining Accuracy: 0.9980 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Epoch: 105 \tTraining Loss: 0.0046 \tTraining Accuracy: 0.9979 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Epoch: 106 \tTraining Loss: 0.0056 \tTraining Accuracy: 0.9979 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Epoch: 107 \tTraining Loss: 0.0051 \tTraining Accuracy: 0.9978 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Epoch: 108 \tTraining Loss: 0.0052 \tTraining Accuracy: 0.9980 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Epoch: 109 \tTraining Loss: 0.0052 \tTraining Accuracy: 0.9980 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Epoch: 110 \tTraining Loss: 0.0050 \tTraining Accuracy: 0.9978 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Epoch: 111 \tTraining Loss: 0.0045 \tTraining Accuracy: 0.9980 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Epoch: 112 \tTraining Loss: 0.0048 \tTraining Accuracy: 0.9979 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Epoch: 113 \tTraining Loss: 0.0042 \tTraining Accuracy: 0.9980 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Epoch: 114 \tTraining Loss: 0.0046 \tTraining Accuracy: 0.9982 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Epoch: 115 \tTraining Loss: 0.0042 \tTraining Accuracy: 0.9983 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Epoch: 116 \tTraining Loss: 0.0045 \tTraining Accuracy: 0.9982 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Epoch: 117 \tTraining Loss: 0.0055 \tTraining Accuracy: 0.9977 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Epoch: 118 \tTraining Loss: 0.0052 \tTraining Accuracy: 0.9976 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Epoch: 119 \tTraining Loss: 0.0050 \tTraining Accuracy: 0.9981 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Epoch: 120 \tTraining Loss: 0.0042 \tTraining Accuracy: 0.9983 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Epoch: 121 \tTraining Loss: 0.0046 \tTraining Accuracy: 0.9982 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Epoch: 122 \tTraining Loss: 0.0045 \tTraining Accuracy: 0.9980 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Epoch: 123 \tTraining Loss: 0.0047 \tTraining Accuracy: 0.9980 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Epoch: 124 \tTraining Loss: 0.0046 \tTraining Accuracy: 0.9981 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Epoch: 125 \tTraining Loss: 0.0047 \tTraining Accuracy: 0.9982 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Epoch: 126 \tTraining Loss: 0.0046 \tTraining Accuracy: 0.9980 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Epoch: 127 \tTraining Loss: 0.0053 \tTraining Accuracy: 0.9979 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Epoch: 128 \tTraining Loss: 0.0047 \tTraining Accuracy: 0.9979 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Epoch: 129 \tTraining Loss: 0.0054 \tTraining Accuracy: 0.9978 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Epoch: 130 \tTraining Loss: 0.0049 \tTraining Accuracy: 0.9980 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Epoch: 131 \tTraining Loss: 0.0047 \tTraining Accuracy: 0.9980 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Epoch: 132 \tTraining Loss: 0.0052 \tTraining Accuracy: 0.9979 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Epoch: 133 \tTraining Loss: 0.0051 \tTraining Accuracy: 0.9980 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9924\n",
            "Epoch: 134 \tTraining Loss: 0.0044 \tTraining Accuracy: 0.9980 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Epoch: 135 \tTraining Loss: 0.0045 \tTraining Accuracy: 0.9980 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Epoch: 136 \tTraining Loss: 0.0044 \tTraining Accuracy: 0.9980 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Epoch: 137 \tTraining Loss: 0.0044 \tTraining Accuracy: 0.9979 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Epoch: 138 \tTraining Loss: 0.0047 \tTraining Accuracy: 0.9980 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Epoch: 139 \tTraining Loss: 0.0048 \tTraining Accuracy: 0.9979 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Epoch: 140 \tTraining Loss: 0.0048 \tTraining Accuracy: 0.9981 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Epoch: 141 \tTraining Loss: 0.0048 \tTraining Accuracy: 0.9982 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Epoch: 142 \tTraining Loss: 0.0048 \tTraining Accuracy: 0.9981 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Epoch: 143 \tTraining Loss: 0.0047 \tTraining Accuracy: 0.9983 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Epoch: 144 \tTraining Loss: 0.0050 \tTraining Accuracy: 0.9979 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Epoch: 145 \tTraining Loss: 0.0052 \tTraining Accuracy: 0.9978 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Epoch: 146 \tTraining Loss: 0.0045 \tTraining Accuracy: 0.9982 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Epoch: 147 \tTraining Loss: 0.0050 \tTraining Accuracy: 0.9980 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Epoch: 148 \tTraining Loss: 0.0050 \tTraining Accuracy: 0.9979 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Epoch: 149 \tTraining Loss: 0.0050 \tTraining Accuracy: 0.9980 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Epoch: 150 \tTraining Loss: 0.0047 \tTraining Accuracy: 0.9980 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Epoch: 151 \tTraining Loss: 0.0040 \tTraining Accuracy: 0.9982 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Epoch: 152 \tTraining Loss: 0.0054 \tTraining Accuracy: 0.9978 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Epoch: 153 \tTraining Loss: 0.0055 \tTraining Accuracy: 0.9977 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Epoch: 154 \tTraining Loss: 0.0048 \tTraining Accuracy: 0.9978 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Epoch: 155 \tTraining Loss: 0.0051 \tTraining Accuracy: 0.9978 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Epoch: 156 \tTraining Loss: 0.0048 \tTraining Accuracy: 0.9978 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Epoch: 157 \tTraining Loss: 0.0043 \tTraining Accuracy: 0.9980 \tValidation Loss: 0.0052 \tValidation Accuracy: 0.9925\n",
            "Traceback (most recent call last):\n",
            "  File \"main_frequentist.py\", line 113, in <module>\n",
            "    run(args.dataset, args.net_type)\n",
            "  File \"main_frequentist.py\", line 89, in run\n",
            "    train_loss, train_acc = train_model(net, optimizer, criterion, train_loader)\n",
            "  File \"main_frequentist.py\", line 38, in train_model\n",
            "    for data, target in train_loader:\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 345, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 841, in _next_data\n",
            "    idx, data = self._get_data()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 808, in _get_data\n",
            "    success, data = self._try_get_data()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 761, in _try_get_data\n",
            "    data = self._data_queue.get(timeout=timeout)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
            "    if not self._poll(timeout):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
            "    return self._poll(timeout)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
            "    r = wait([self], timeout)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 905, in wait\n",
            "    selector.register(obj, selectors.EVENT_READ)\n",
            "  File \"/usr/lib/python3.6/selectors.py\", line 351, in register\n",
            "    key = super().register(fileobj, events, data)\n",
            "  File \"/usr/lib/python3.6/selectors.py\", line 237, in register\n",
            "    key = SelectorKey(fileobj, self._fileobj_lookup(fileobj), events, data)\n",
            "  File \"<string>\", line 14, in __new__\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}